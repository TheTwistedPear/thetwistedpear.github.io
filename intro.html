<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 General Features of Psychological Tests | The Twisted Pear</title>
  <meta name="description" content="The learning materials for Ability Asssessment." />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 General Features of Psychological Tests | The Twisted Pear" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The learning materials for Ability Asssessment." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 General Features of Psychological Tests | The Twisted Pear" />
  
  <meta name="twitter:description" content="The learning materials for Ability Asssessment." />
  

<meta name="author" content="Kevin Rowley" />


<meta name="date" content="2025-03-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="NDSM.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Assessment of Psychological Attributes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> General Features of Psychological Tests</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#types-of-psychological-test"><i class="fa fa-check"></i><b>2.1</b> Types of Psychological Test</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#specific-features-of-each-type-of-test"><i class="fa fa-check"></i><b>2.1.1</b> Specific Features of each Type of Test</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#using-tests-for-occupational-purposes"><i class="fa fa-check"></i><b>2.2</b> Using Tests for Occupational Purposes</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#good-practice-for-psychological-testing"><i class="fa fa-check"></i><b>2.2.1</b> Good Practice for Psychological Testing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#the-usefulness-of-tests-in-selection-for-jobs"><i class="fa fa-check"></i><b>2.3</b> The Usefulness of Tests in Selection for Jobs</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#validity-generalization-and-meta-analysis"><i class="fa fa-check"></i><b>2.4</b> Validity Generalization and Meta-analysis</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#implications-from-validity-generalization"><i class="fa fa-check"></i><b>2.5</b> Implications from Validity Generalization</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#determinants-of-job-performance"><i class="fa fa-check"></i><b>2.6</b> Determinants of Job Performance</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#what-is-meant-by-general-mental-ability-gma"><i class="fa fa-check"></i><b>2.7</b> What is meant by General Mental Ability (GMA)</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#criterion-related-validity-coefficients-and-the-coefficient-of-determination"><i class="fa fa-check"></i><b>2.8</b> Criterion-related Validity Coefficients and the Coefficient of Determination</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#criterion-related-validity-and-multiple-correlation"><i class="fa fa-check"></i><b>2.9</b> Criterion-Related Validity and Multiple-Correlation</a></li>
<li class="chapter" data-level="2.10" data-path="intro.html"><a href="intro.html#indicative-general-references-on-selection"><i class="fa fa-check"></i><b>2.10</b> Indicative General References on Selection</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="NDSM.html"><a href="NDSM.html"><i class="fa fa-check"></i><b>3</b> The Normal Distribution and scales of Measurement</a>
<ul>
<li class="chapter" data-level="3.1" data-path="NDSM.html"><a href="NDSM.html#SSPERC"><i class="fa fa-check"></i><b>3.1</b> Percentiles</a></li>
<li class="chapter" data-level="3.2" data-path="NDSM.html"><a href="NDSM.html#standard-scores-z"><i class="fa fa-check"></i><b>3.2</b> Standard scores (z)</a></li>
<li class="chapter" data-level="3.3" data-path="NDSM.html"><a href="NDSM.html#normalising-z-scores"><i class="fa fa-check"></i><b>3.3</b> Normalising z scores</a></li>
<li class="chapter" data-level="3.4" data-path="NDSM.html"><a href="NDSM.html#standardised-scores"><i class="fa fa-check"></i><b>3.4</b> Standardised scores</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="reliability.html"><a href="reliability.html"><i class="fa fa-check"></i><b>4</b> The Reliability of Measurement</a>
<ul>
<li class="chapter" data-level="4.1" data-path="reliability.html"><a href="reliability.html#reliability-1"><i class="fa fa-check"></i><b>4.1</b> Reliability</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="reliability.html"><a href="reliability.html#few-items-will-not-represent-the-whole-domain-of-the-construct"><i class="fa fa-check"></i><b>4.1.1</b> Few items will not represent the whole domain of the construct</a></li>
<li class="chapter" data-level="4.1.2" data-path="reliability.html"><a href="reliability.html#difficulty-levels-cannot-be-properly-varied-with-few-items-and-so-cannot-reveal-a-range-a-difference-between-people."><i class="fa fa-check"></i><b>4.1.2</b> Difficulty levels cannot be properly varied with few items and so cannot reveal a range a difference between people.</a></li>
<li class="chapter" data-level="4.1.3" data-path="reliability.html"><a href="reliability.html#any-one-item-may-be-poorly-constructed"><i class="fa fa-check"></i><b>4.1.3</b> Any one item may be poorly constructed</a></li>
<li class="chapter" data-level="4.1.4" data-path="reliability.html"><a href="reliability.html#any-one-item-may-offer-advantage-or-disadvantage-to-the-test-taker-because-of-their-previous-experience"><i class="fa fa-check"></i><b>4.1.4</b> Any one item may offer advantage or disadvantage to the test taker because of their previous experience</a></li>
<li class="chapter" data-level="4.1.5" data-path="reliability.html"><a href="reliability.html#any-one-item-may-be-affected-by-very-temporary-events"><i class="fa fa-check"></i><b>4.1.5</b> Any one item may be affected by very temporary events</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="reliability.html"><a href="reliability.html#reliability-and-classical-test-theory"><i class="fa fa-check"></i><b>4.2</b> Reliability and Classical Test Theory</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="reliability.html"><a href="reliability.html#determining-the-reliability-coefficients"><i class="fa fa-check"></i><b>4.2.1</b> Determining the Reliability Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="reliability.html"><a href="reliability.html#test-retest-methods"><i class="fa fa-check"></i><b>4.2.2</b> Test-Retest Methods</a></li>
<li class="chapter" data-level="4.2.3" data-path="reliability.html"><a href="reliability.html#alternate-form-methods-parallel-form-methods"><i class="fa fa-check"></i><b>4.2.3</b> Alternate Form Methods (Parallel form methods)</a></li>
<li class="chapter" data-level="4.2.4" data-path="reliability.html"><a href="reliability.html#split-half-methods"><i class="fa fa-check"></i><b>4.2.4</b> Split-half Methods</a></li>
<li class="chapter" data-level="4.2.5" data-path="reliability.html"><a href="reliability.html#internal-consistency-methods"><i class="fa fa-check"></i><b>4.2.5</b> Internal Consistency Methods</a></li>
<li class="chapter" data-level="4.2.6" data-path="reliability.html"><a href="reliability.html#reliability-and-the-effect-of-combining-scores-from-separate-tests"><i class="fa fa-check"></i><b>4.2.6</b> Reliability and the Effect of Combining Scores from Separate Tests</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="reliability.html"><a href="reliability.html#assumptions-of-internal-consistency-methods"><i class="fa fa-check"></i><b>4.3</b> Assumptions of Internal Consistency Methods</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="reliability.html"><a href="reliability.html#unidimensionality"><i class="fa fa-check"></i><b>4.3.1</b> Unidimensionality</a></li>
<li class="chapter" data-level="4.3.2" data-path="reliability.html"><a href="reliability.html#reliability-models"><i class="fa fa-check"></i><b>4.3.2</b> Reliability Models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="reliability.html"><a href="reliability.html#GTHEORY"><i class="fa fa-check"></i><b>4.4</b> Generalisability Theory</a></li>
<li class="chapter" data-level="4.5" data-path="reliability.html"><a href="reliability.html#using-reliability-coefficients-to-calculate-confidence-intervals"><i class="fa fa-check"></i><b>4.5</b> Using Reliability coefficients to Calculate Confidence Intervals</a></li>
<li class="chapter" data-level="4.6" data-path="reliability.html"><a href="reliability.html#calculating-the-standard-error-of-measurement-sem"><i class="fa fa-check"></i><b>4.6</b> Calculating the Standard Error of Measurement (SEM)</a></li>
<li class="chapter" data-level="4.7" data-path="reliability.html"><a href="reliability.html#indicative-reading"><i class="fa fa-check"></i><b>4.7</b> Indicative Reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="validity.html"><a href="validity.html"><i class="fa fa-check"></i><b>5</b> The validity of measurement</a>
<ul>
<li class="chapter" data-level="5.0.1" data-path="validity.html"><a href="validity.html#content-validity"><i class="fa fa-check"></i><b>5.0.1</b> Content validity</a></li>
<li class="chapter" data-level="5.0.2" data-path="validity.html"><a href="validity.html#criterion-related-validity"><i class="fa fa-check"></i><b>5.0.2</b> Criterion-related validity</a></li>
<li class="chapter" data-level="5.0.3" data-path="validity.html"><a href="validity.html#construct-validity"><i class="fa fa-check"></i><b>5.0.3</b> Construct validity</a></li>
<li class="chapter" data-level="5.1" data-path="validity.html"><a href="validity.html#the-relationship-between-reliability-and-validity"><i class="fa fa-check"></i><b>5.1</b> The relationship between reliability and validity:</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="outcomes.html"><a href="outcomes.html"><i class="fa fa-check"></i><b>6</b> Tests, Decisions and Outcomes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="outcomes.html"><a href="outcomes.html#test-validity-selection-ratio-base-rate-and-the-quality-of-decisions."><i class="fa fa-check"></i><b>6.1</b> Test Validity, Selection Ratio, Base Rate and the Quality of Decisions.</a></li>
<li class="chapter" data-level="6.2" data-path="outcomes.html"><a href="outcomes.html#calculating-the-probabilities-of-decision-outcomes"><i class="fa fa-check"></i><b>6.2</b> Calculating the Probabilities of Decision Outcomes</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="outcomes.html"><a href="outcomes.html#what-is-the-incremental-validity"><i class="fa fa-check"></i><b>6.2.1</b> What is the Incremental validity?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="outcomes.html"><a href="outcomes.html#calculating-the-cash-benefits-of-a-selection-strategy"><i class="fa fa-check"></i><b>6.3</b> Calculating the Cash Benefits of a Selection Strategy</a></li>
<li class="chapter" data-level="6.4" data-path="outcomes.html"><a href="outcomes.html#indicative-reading-1"><i class="fa fa-check"></i><b>6.4</b> Indicative Reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="TBF.html"><a href="TBF.html"><i class="fa fa-check"></i><b>7</b> Test Bias and Fairness</a>
<ul>
<li class="chapter" data-level="7.1" data-path="TBF.html"><a href="TBF.html#the-potential-for-adverse-impact"><i class="fa fa-check"></i><b>7.1</b> The Potential for Adverse Impact</a></li>
<li class="chapter" data-level="7.2" data-path="TBF.html"><a href="TBF.html#how-to-investigate-test-bias"><i class="fa fa-check"></i><b>7.2</b> How to investigate test bias</a></li>
<li class="chapter" data-level="7.3" data-path="TBF.html"><a href="TBF.html#content-validity-and-dif-analysis"><i class="fa fa-check"></i><b>7.3</b> Content Validity and DIF Analysis</a></li>
<li class="chapter" data-level="7.4" data-path="TBF.html"><a href="TBF.html#the-fair-use-of-tests"><i class="fa fa-check"></i><b>7.4</b> The Fair Use of Tests</a></li>
<li class="chapter" data-level="7.5" data-path="TBF.html"><a href="TBF.html#sources-of-information-and-advice"><i class="fa fa-check"></i><b>7.5</b> Sources of Information and Advice</a></li>
<li class="chapter" data-level="7.6" data-path="TBF.html"><a href="TBF.html#from-the-website"><i class="fa fa-check"></i><b>7.6</b> From the website:</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="TBF.html"><a href="TBF.html#whats-included-in-the-equality-act"><i class="fa fa-check"></i><b>7.6.1</b> What’s included in the Equality Act?</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="TBF.html"><a href="TBF.html#indicative-academic-reading"><i class="fa fa-check"></i><b>7.7</b> Indicative Academic Reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="TBG.html"><a href="TBG.html"><i class="fa fa-check"></i><b>8</b> Test Feedback Guidance</a></li>
<li class="chapter" data-level="9" data-path="SP.html"><a href="SP.html"><i class="fa fa-check"></i><b>9</b> Statistics Primer</a>
<ul>
<li class="chapter" data-level="9.1" data-path="SP.html"><a href="SP.html#SPFD"><i class="fa fa-check"></i><b>9.1</b> Frequency distributions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="SP.html"><a href="SP.html#drawing-frequency-distributions"><i class="fa fa-check"></i><b>9.1.1</b> Drawing frequency distributions</a></li>
<li class="chapter" data-level="9.1.2" data-path="SP.html"><a href="SP.html#grouped-frequency-distribution"><i class="fa fa-check"></i><b>9.1.2</b> Grouped frequency distribution</a></li>
<li class="chapter" data-level="9.1.3" data-path="SP.html"><a href="SP.html#skewed-distributions"><i class="fa fa-check"></i><b>9.1.3</b> Skewed distributions</a></li>
<li class="chapter" data-level="9.1.4" data-path="SP.html"><a href="SP.html#SPND"><i class="fa fa-check"></i><b>9.1.4</b> The normal distribution curve</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="SP.html"><a href="SP.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>9.2</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="SP.html"><a href="SP.html#mode-median-mean"><i class="fa fa-check"></i><b>9.2.1</b> Mode, Median, Mean</a></li>
<li class="chapter" data-level="9.2.2" data-path="SP.html"><a href="SP.html#when-to-use-the-mode-median-or-mean"><i class="fa fa-check"></i><b>9.2.2</b> When to use the mode, median or mean</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="SP.html"><a href="SP.html#measures-of-dispersion-or-variability"><i class="fa fa-check"></i><b>9.3</b> Measures of dispersion or variability</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="SP.html"><a href="SP.html#SPVAR"><i class="fa fa-check"></i><b>9.3.1</b> The concept of variability</a></li>
<li class="chapter" data-level="9.3.2" data-path="SP.html"><a href="SP.html#SPIQR"><i class="fa fa-check"></i><b>9.3.2</b> Range; Interquartile range</a></li>
<li class="chapter" data-level="9.3.3" data-path="SP.html"><a href="SP.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>9.3.3</b> Variance and standard deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="SPZPER.html"><a href="SPZPER.html"><i class="fa fa-check"></i><b>10</b> z scores and percentiles</a>
<ul>
<li class="chapter" data-level="10.0.1" data-path="SPZPER.html"><a href="SPZPER.html#standard-deviation-of-the-normal-curve-z-scores"><i class="fa fa-check"></i><b>10.0.1</b> Standard deviation of the normal curve: z scores</a></li>
<li class="chapter" data-level="10.0.2" data-path="SPZPER.html"><a href="SPZPER.html#using-normal-curve-z-tables"><i class="fa fa-check"></i><b>10.0.2</b> Using normal curve (z) tables</a></li>
<li class="chapter" data-level="10.0.3" data-path="SPZPER.html"><a href="SPZPER.html#comparing-scores-using-z-values"><i class="fa fa-check"></i><b>10.0.3</b> Comparing scores using z values</a></li>
<li class="chapter" data-level="10.0.4" data-path="SPZPER.html"><a href="SPZPER.html#z-scores-and-percentiles"><i class="fa fa-check"></i><b>10.0.4</b> z-scores and percentiles</a></li>
<li class="chapter" data-level="10.0.5" data-path="SPZPER.html"><a href="SPZPER.html#calculating-percentiles-from-a-frequency-distribution"><i class="fa fa-check"></i><b>10.0.5</b> Calculating percentiles from a frequency distribution</a></li>
<li class="chapter" data-level="10.0.6" data-path="SPZPER.html"><a href="SPZPER.html#t-scores-stens-and-stanines"><i class="fa fa-check"></i><b>10.0.6</b> T scores, stens and stanines</a></li>
<li class="chapter" data-level="10.1" data-path="SPZPER.html"><a href="SPZPER.html#standard-error-and-confidence-limits"><i class="fa fa-check"></i><b>10.1</b> Standard error and confidence limits</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="SPZPER.html"><a href="SPZPER.html#the-concept-of-standard-error"><i class="fa fa-check"></i><b>10.1.1</b> The concept of standard error</a></li>
<li class="chapter" data-level="10.1.2" data-path="SPZPER.html"><a href="SPZPER.html#standard-error-of-measurement"><i class="fa fa-check"></i><b>10.1.2</b> Standard error of measurement</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="SPZPER.html"><a href="SPZPER.html#correlation-coefficients-and-scattergrams"><i class="fa fa-check"></i><b>10.2</b> Correlation coefficients and scattergrams</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="SPZPER.html"><a href="SPZPER.html#the-concept-of-correlation"><i class="fa fa-check"></i><b>10.2.1</b> The concept of correlation</a></li>
<li class="chapter" data-level="10.2.2" data-path="SPZPER.html"><a href="SPZPER.html#scattergrams"><i class="fa fa-check"></i><b>10.2.2</b> Scattergrams</a></li>
<li class="chapter" data-level="10.2.3" data-path="SPZPER.html"><a href="SPZPER.html#pearson-product-moment-correlation"><i class="fa fa-check"></i><b>10.2.3</b> Pearson product moment correlation</a></li>
<li class="chapter" data-level="10.2.4" data-path="SPZPER.html"><a href="SPZPER.html#spearman-rank-correlation-rho"><i class="fa fa-check"></i><b>10.2.4</b> Spearman Rank correlation (rho)</a></li>
<li class="chapter" data-level="10.2.5" data-path="SPZPER.html"><a href="SPZPER.html#effect-of-range-on-correlation"><i class="fa fa-check"></i><b>10.2.5</b> Effect of range on correlation</a></li>
<li class="chapter" data-level="10.2.6" data-path="SPZPER.html"><a href="SPZPER.html#regression"><i class="fa fa-check"></i><b>10.2.6</b> Regression</a></li>
<li class="chapter" data-level="10.2.7" data-path="SPZPER.html"><a href="SPZPER.html#multiple-regression"><i class="fa fa-check"></i><b>10.2.7</b> Multiple regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="RTS.html"><a href="RTS.html"><i class="fa fa-check"></i><b>11</b> Road to (Assignment) Submission</a>
<ul>
<li class="chapter" data-level="11.1" data-path="RTS.html"><a href="RTS.html#general"><i class="fa fa-check"></i><b>11.1</b> General</a></li>
<li class="chapter" data-level="11.2" data-path="RTS.html"><a href="RTS.html#short-glossary"><i class="fa fa-check"></i><b>11.2</b> Short Glossary</a></li>
<li class="chapter" data-level="11.3" data-path="RTS.html"><a href="RTS.html#TM"><i class="fa fa-check"></i><b>11.3</b> Part 1 - The Technical Manual</a>
<ul>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#starting-points"><i class="fa fa-check"></i>Starting Points</a></li>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#introduction-section"><i class="fa fa-check"></i>Introduction Section</a></li>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#method-section"><i class="fa fa-check"></i>Method Section</a></li>
<li class="chapter" data-level="11.3.1" data-path="RTS.html"><a href="RTS.html#checklist-for-part-1"><i class="fa fa-check"></i><b>11.3.1</b> Checklist for Part 1</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="RTS.html"><a href="RTS.html#part-2---sample-feedback"><i class="fa fa-check"></i><b>11.4</b> Part 2 - Sample Feedback</a>
<ul>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#starting-points-1"><i class="fa fa-check"></i>Starting Points</a></li>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#the-report"><i class="fa fa-check"></i>The Report</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="RTS.html"><a href="RTS.html#part-3---critical-reflection"><i class="fa fa-check"></i><b>11.5</b> Part 3 - Critical Reflection</a></li>
<li class="chapter" data-level="11.6" data-path="RTS.html"><a href="RTS.html#appendix"><i class="fa fa-check"></i><b>11.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="RTS.html"><a href="RTS.html#checklist-for-appendix"><i class="fa fa-check"></i>Checklist for Appendix</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="SCN.html"><a href="SCN.html"><i class="fa fa-check"></i><b>12</b> Scenarios</a>
<ul>
<li class="chapter" data-level="12.1" data-path="SCN.html"><a href="SCN.html#psychometric-consultancy-at-birley-house"><i class="fa fa-check"></i><b>12.1</b> Psychometric consultancy at Birley House</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="SCN.html"><a href="SCN.html#the-situation"><i class="fa fa-check"></i><b>12.1.1</b> The Situation</a></li>
<li class="chapter" data-level="12.1.2" data-path="SCN.html"><a href="SCN.html#managers-letter"><i class="fa fa-check"></i><b>12.1.2</b> Manager’s Letter</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="SCN.html"><a href="SCN.html#psychometric-consultancy-at-hmp-birley"><i class="fa fa-check"></i><b>12.2</b> Psychometric consultancy at HMP Birley</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="SCN.html"><a href="SCN.html#the-situation-1"><i class="fa fa-check"></i><b>12.2.1</b> The Situation</a></li>
<li class="chapter" data-level="12.2.2" data-path="SCN.html"><a href="SCN.html#letter-from-the-governor"><i class="fa fa-check"></i><b>12.2.2</b> Letter from the Governor</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="misc.html"><a href="misc.html"><i class="fa fa-check"></i><b>13</b> Miscellaneous</a>
<ul>
<li class="chapter" data-level="13.1" data-path="misc.html"><a href="misc.html#mischead"><i class="fa fa-check"></i><b>13.1</b> What Do You Mean by Sub-Heading Levels?</a>
<ul>
<li class="chapter" data-level="" data-path="misc.html"><a href="misc.html#level-1-major-section-introduction-etc"><i class="fa fa-check"></i>Level 1 (Major Section, Introduction etc)</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="misc.html"><a href="misc.html#BCID"><i class="fa fa-check"></i><b>13.2</b> Boundary Conditions In-depth</a></li>
<li class="chapter" data-level="13.3" data-path="misc.html"><a href="misc.html#RAW"><i class="fa fa-check"></i><b>13.3</b> What Even Are Raw Scores?</a></li>
<li class="chapter" data-level="13.4" data-path="misc.html"><a href="misc.html#REGREP"><i class="fa fa-check"></i><b>13.4</b> Can’t Seem to Register a Registered Report</a></li>
<li class="chapter" data-level="13.5" data-path="misc.html"><a href="misc.html#ng-percentiles"><i class="fa fa-check"></i><b>13.5</b> *%$@#ng Percentiles!?</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Twisted Pear</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> General Features of Psychological Tests<a href="intro.html#intro" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Psychological tests are commonly described as objective and standardised measures of a sample of behaviour (e.g. Anastasi &amp; Urbina, 1997; Janda, 1998). A test is objective if its administration, scoring and interpretation are clearly specified and replicable. A test is standardised if these specifications are adhered to and uniformly applied. A standardised test often uses a large comparison group (i.e. norm group) for interpretation of test scores. A test is a sample of behaviour if its content or administration involves only some of the possible activities and/or some of the possible circumstances with which the test is concerned. For example, a test might be concerned with mathematical ability. The test may involve several mathematical problems to be solved without a calculator and with a time limit. This test will contain only a sample of the possible mathematical problems that could be included. Furthermore, it samples mathematical problem solving behaviour under quite specific circumstances i.e. without a calculator, with a time limit, and possibly in an anxiety provoking situation. Thus, quite apart from the specific content of the test, the testing situation itself should be viewed as a sample of all the possible circumstances where solving maths problems could be demonstrated.
Tests, then, are concerned with samples of behaviour. However, the behaviour being sampled is often regarded as an indirect index or sign of some underlying concept such as ability (e.g. verbal, numerical, spatial) or personality (e.g. extraversion, agreeableness, etc). Such concepts have four features in common:</p>
<p>• They are concepts used to summarise and describe observed consistencies in behaviour.
• These concepts are usually regarded as theoretical constructs that encompass more than the original set of observations.
• There is no single set of questions or items that can be used to measure the construct. There must instead be a sampling of relevant questions/items from the universe of items within the construct domain.
• The construct must always be related, either directly or indirectly, to observable behaviour or experience.</p>
<p>Tests that claim to measure intelligence are clearly sampling behaviour that is considered to be a sign of a broad theoretical concept. The same may be said of more narrow measurements such as mathematical ability, or even tests that attempt to measure the concept of ‘knowledge’ of a subject area. However, it should be clear that the aspiration of tests to measure broad constructs must always be limited by the fact that they involve only a sample of behaviour which may not be representative.</p>
<p>There can be some tests that are narrow enough in their concern that they are often regarded as directly sampling the almost complete behaviour e.g. a typing test, spot welding test and other ‘work’ samples where there is a ‘point-to-point’ correspondence between behaviours assessed through the sample and some of the behaviours required within the job. Of course, there is still problem that the circumstances of testing may be unrepresentative.</p>
<div id="types-of-psychological-test" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Types of Psychological Test<a href="intro.html#types-of-psychological-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Psychological tests can be broadly categorised according to the type of construct they claim to measure:</p>
<p>Intelligence tests: One of the oldest types of psychological test is the ‘intelligence’ test which claims to measure overall basic reasoning ability. Modern versions of these tests include the Wechsler Adult Intelligence Scale (WAIS- IV), the Stanford-Binet test (for ages 4-17) and the British Ability Scales (for ages 2 ½ -17 ½). These three tests have to be administered on an individual basis. Other intelligence tests can be administered to groups e.g. Raven’s Progressive Matrices, The Culture Fair Tests, and the Alice Heim 3 (AH3).</p>
<p>Specific Ability tests: The above intelligence tests measure very general ability, other types of test are designed to assess more specific ability factors, the most important of which are considered to be verbal ability, spatial ability and mathematical reasoning (Kline, 2000). For example, the Watson-Glaser Critical Thinking Appraisal measures verbal reasoning and is used within graduate recruitment and management selection. Sub-scales within general intelligence tests may also be considered as tests of specific ability e.g. the arithmetic scale of the WAIS. There are also a number of tests that assess very specific factors e.g. the Purdue Pegboard (a measure of finger, hand and arm dexterity).</p>
<ul>
<li><p>Aptitude tests: Occasionally, the above specific ability measures are referred to as aptitude tests. However, it is more usual for the term ‘aptitude test’ to be used when the test contains a mixture of underlying abilities needed for a particular course, job role or occupation (e.g. General Clerical Test, Computer aptitude test).</p></li>
<li><p>Achievement (or attainment) tests: The above ability and aptitude tests often claim to measure the potential for learning or acquiring a new skill, in that they aim to assess necessary underlying abilities. In contrast, achievement tests measure the level of knowledge or skill attained by an individual through instruction (e.g. university examinations).</p></li>
<li><p>Interest tests and Values tests: Typically tests of interest contain a large number of items about whether various activities, situations and types of people are liked or disliked e.g. the Vocational Interest Measure (VIM), The Strong-Campbell Interest Inventory (SCII). Tests of values attempt to measure a person’s basic philosophy and orientation to the world e.g. The Study of Values, the Rokeach Value Survey.</p></li>
<li><p>Personality tests: these usually contain a large number of items about feelings and behaviour and attempt to measure fundamental differences in temperament e.g. The Californian Psychological Inventory (CPI), the Myers-Briggs Type indicator (MBTI), The 16 Personality Factors Test (16PF), Quintax.</p></li>
<li><p>Integrity tests: These tests attempt to identify potentially counterproductive or dishonest employees. Some of these tests may be described as overt tests in that they ask directly about dishonest activities and attitudes towards dishonesty e.g. the London House Personnel Selection Inventory; the Reid Report. Other integrity tests may be described as covert tests in that they aim to measure aspects of personality related to counterproductive behaviour, such as unreliability and carelessness e.g. Giotto</p></li>
</ul>
<div id="specific-features-of-each-type-of-test" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Specific Features of each Type of Test<a href="intro.html#specific-features-of-each-type-of-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="tests-of-maximal-performance" class="section level4 hasAnchor" number="2.1.1.1">
<h4><span class="header-section-number">2.1.1.1</span> Tests of Maximal Performance<a href="intro.html#tests-of-maximal-performance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tests of intelligence, specific ability, aptitude and achievement (for which items have a correct answer) are often described as tests of maximal performance (how well a person can do). Such tests most commonly consist of multiple-choice items. Here, an item presents a problem to be solved (termed the stem), followed by a choice of possible answers (typically around five and termed the response set) only one of which is correct (termed the keyed response). The incorrect answers are termed distracters. These tests of maximal performance can be classified as either Power tests, speed tests or speeded tests:</p>
<ul>
<li><p>Power tests have no time limit, or a limit that is long enough so that about 90% of test takers can attempt all items. Such tests usually have items that gradually increase in difficulty so that, for most people, a limit in the ability to solve the problems is reached.</p></li>
<li><p>Speed tests have a time limit that prevents all items from being attempted, but which if given without a time limit would be correctly solved by most people. Here it is speed of response that limits performance.</p></li>
<li><p>Speeded tests will fall somewhere between the two extremes above. There is a time limit that affects the number of items correctly solved and the tests have some difficulty, often gradually increasing difficulty.</p></li>
<li><p>Tests of maximal performance can be further classified as either norm-referenced or criterion-referenced. With norm-referenced tests, a person’s score (how many items were responded to correctly) is compared with others (known as a norm group) to establish a relative position. With criterion-referenced tests, the concern is with a standard of performance, the presence or absence of a certain level of skill, knowledge or achievement. Such use, sometimes known as mastery testing, involves classification (e.g. pass or fail) or diagnosis (identification of what action needs to be taken).</p></li>
</ul>
<p>With tests of maximal performance, the behaviour being sampled often appears quite directly related to the construct e.g. the measurement of spatial ability may involve the mental rotation of three-dimensional drawings.</p>
</div>
<div id="tests-of-typical-performance-normative-and-ipsative" class="section level4 hasAnchor" number="2.1.1.2">
<h4><span class="header-section-number">2.1.1.2</span> Tests of Typical Performance: Normative and Ipsative<a href="intro.html#tests-of-typical-performance-normative-and-ipsative" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tests of personality, interest and integrity (for which there are no ‘correct’ answers) are often described as tests of typical performance (what the person typically does). Such tests commonly consist of items that ask questions about behaviour, beliefs or feelings (e.g. Do you listen carefully when talking with others?), to which a yes /no response is required. Alternatively, the items are statements (e.g. I am often impatient to make my point during conversations), to which either a true/false response is required, or there is a rating scale with 5, 7 or 9 points. Rating scales require an indication of the extent to which the statement is true of the respondent, or the strength of agreement with the statement. Most tests of typical performance measure more than one construct, so that a number of items may be concerned with, for example, conscientiousness, other items may be concerned with openness to ideas, and so on. Regardless of whether the test measures just one construct or many, the response formats so far described allow respondents a free choice of agreeing or not agreeing with each question or statement. Such ‘free choice’ formats are sometimes termed normative measures.</p>
<p>A few tests of typical performance contain items that present a forced choice between statements. Here, an item contains more than one statement and there is a requirement to indicate which is most true. Alternatively, there is a requirement to rank order the statements from most to least true.
Below is an example showing just two items from a forced choice test:</p>
<p>Please indicate which of the following statements is most true of you. For each item tick only one box [ ].
1.
I am almost always on time for appointments [ ]
I am very intrigued by new ideas [ ]</p>
<ol start="2" style="list-style-type: decimal">
<li>Once started I usually finish a task [ ]
I have varied interests [ ]</li>
</ol>
<p>Note that each item above requires a choice involving more than one construct. The first statement within each item above appears to be concerned with conscientiousness and the second statement appears to be concerned with openness to ideas. Thus, when completing a forced choice measure with many such items, the greater the number of statements that are endorsed for any one construct within the items (e.g. conscientiousness), then the lower must be the number of statements endorsed for the other construct within the items (e.g. openness to ideas). Because of this, it is not possible to score very highly or very lowly on all constructs within forced choice measures. In fact, because every item receives a score, either for one construct or another, the total of scores over all constructs measured will be the same for all respondents; it will just be the distribution of scores between the constructs that will differ. This forced-choice format is sometimes used to reduce socially desirable responding, as with the above example, where both options within an item appear to be equally desirable.</p>
<p>Forced-choice measures are sometimes termed ipsative measures. From the above description, their two key features may be summarised as:</p>
<p>• The options within each item of the test require choices involving more than one construct
• The total score over the constructs being measured will sum to a constant number for all individuals</p>
<p>Good ipsative measures are difficult to construct. Also, because a total score is shared out between the constructs, such tests are better suited to measuring the relative strengths of preferences within individuals rather than absolute strengths between individuals (for which normative measures are best suited).
With tests of typical performance the behaviour being sampled can appear quite indirectly related to the construct i.e. the behaviour here is responding to statements and questions, perhaps accurately, through the judgement of one’s feelings, behaviours, attitudes, etc.</p>
</div>
</div>
</div>
<div id="using-tests-for-occupational-purposes" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Using Tests for Occupational Purposes<a href="intro.html#using-tests-for-occupational-purposes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The main uses for tests within occupational settings may be categorised as:</p>
<p>• Part of the selection process for entering an organisation or for promotion within an organisation
• Aids for team building, managing change and other organisational issues
• Aids to personal development or career guidance</p>
<p>Whatever the particular use for the tests, there should always be a clear focus on the assessment needs, and a concern with good practice. The British Psychological Society (the BPS) has a Code of</p>
<div id="good-practice-for-psychological-testing" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Good Practice for Psychological Testing<a href="intro.html#good-practice-for-psychological-testing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><a href="http://www.psychtesting.org.uk/the-ptc/guidelinesandinformation.cfm" class="uri">http://www.psychtesting.org.uk/the-ptc/guidelinesandinformation.cfm</a>
This code outlines what is expected by the BPS when using tests, and includes:</p>
<p>Responsibility for Competence e.g. ensuring that test users meet all the standards of competence and endeavour to develop/enhance this competence.</p>
<p>Appropriate Procedures and Techniques e.g. ensuring that the test is appropriate for its intended purpose. Storing test materials securely, and ensuring that no unqualified person has access to them. Keeping test results securely, and in a form suitable for developing norms, validation and monitoring bias.</p>
<p>Client Welfare e.g. obtaining informed consent of potential test takers, making sure that they understand what tests will be used, what will be done with their results and who will have access to them. Ensuring that test takers are well informed and well prepared for the test session. Providing the test taker and other authorised persons with feedback about the results. The feedback should make clear the implications of the results, and be in a style appropriate to the reader’s/hearer’s level of understanding. Due consideration should be given to factors such as gender, ethnicity, age, disability and specific needs, educational background and level of ability in using and interpreting the results of tests.</p>
<p>The particular details for good practice will be derived from the particular purpose for testing. For example, a code of practice for Careers Guidance might include:</p>
<p>• The starting point will always be the particular needs of the individual client.</p>
<p>• The service provider should be aware of the competencies required within different occupations and endeavour to assess the level of fit between applicant and job, which may include tests of interest, style, motivation and ability</p>
<p>• Service providers will be trained to meet the British Psychological Society (BPS) standards for occupational testing</p>
<p>• Test users will monitor the extent to which the tests are fair for all</p>
<p>• No client will be given an inappropriate or unnecessary test</p>
<p>• All clients will have the right to confidential feedback</p>
<p>• The client has ownership of the test results and no copies should be kept without prior consent</p>
<p>• All materials should be kept securely and with access only by appropriately trained users.</p>
</div>
</div>
<div id="the-usefulness-of-tests-in-selection-for-jobs" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> The Usefulness of Tests in Selection for Jobs<a href="intro.html#the-usefulness-of-tests-in-selection-for-jobs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ability tests and personality questionnaires are widely used within employee selection. An older survey by Hodgkinson and Payne (1998) revealed the popularity of these methods for graduate selection is not new.</p>
<div class="figure"><span style="display:block;" id="fig:tabpng"></span>
<img src="Floats/Ch1/Tab1.png" alt="Table 1: Selection Procedure usage (percentage of organisations) for Graduates  in three European Countries. Adapted from Hodgkinson and Payne (1998)." width="394" />
<p class="caption">
Figure 2.1: Table 1: Selection Procedure usage (percentage of organisations) for Graduates in three European Countries. Adapted from Hodgkinson and Payne (1998).
</p>
</div>
<p>A more recent survey by Zibarras and Woods (2010) revealed the higher use of structured interviews along with ability/aptitiude tests in larger organisations.</p>
<p>Importantly, good tests offer reliable and valid measurement. The specific meanings of these two terms will be explored in detail later. For now, we shall describe reliability as consistent measurement and validity as meaningful measurement.</p>
<p>One aspect of the meaningfulness of measurement is the extent to which a measure (or score) is related to external criteria (i.e. criterion-related validity)
Within occupational testing, this criterion may be job performance. There will of course be many ways of measuring this criterion and thus many potential ways of establishing criterion-related validity.</p>
<p>Criterion-related validity is established through obtaining a set of test scores from a large group of people and then obtaining some measure of criterion performance for these same people (e.g. job performance scores). The two sets of scores can then be correlated to give what is known as a criterion-related validity coefficient. Since these validity coefficients are correlation coefficients, their values will range from 0 to 1.00, and are usually symbolised as rxy i.e. the correlation (r) between test scores (x) and criterion scores (y).</p>
<p>Table 2 overleaf shows reported criterion-related validity coefficients for a number of selection methods, including general mental ability (GMA), for job performance (from a classic 1998 meta-analysis).</p>
<caption>
<span id="tab:tabtwo">Table 2.1: </span>
</caption>
<div custom-style="Table Caption">
<em>Table 2: Criterion-related Validity for Overall Job Performance of Selection Methods, and GMA in combination with these methods. Adapted From Schmidt &amp; Hunter (1998).</em>
</div>
<table>
<thead>
<tr class="header">
<th align="left">Personnel.measures</th>
<th align="left">Validity.rxy.</th>
<th align="left">Multiple.R</th>
<th align="left">Gain.in.validity.from.adding.supplement</th>
<th align="left">X..increase.in.Validity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">GMA tests</td>
<td align="left">0.56</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Integrity tests</td>
<td align="left">0.38</td>
<td align="left">0.67</td>
<td align="left">0.11</td>
<td align="left">20%</td>
</tr>
<tr class="odd">
<td align="left">Conscientiousness tests</td>
<td align="left">0.30</td>
<td align="left">0.65</td>
<td align="left">0.09</td>
<td align="left">16%</td>
</tr>
<tr class="even">
<td align="left">Employment interviews (all types)</td>
<td align="left">0.35</td>
<td align="left">0.59</td>
<td align="left">0.03</td>
<td align="left">5%</td>
</tr>
<tr class="odd">
<td align="left">Peer ratings</td>
<td align="left">0.36</td>
<td align="left">0.57</td>
<td align="left">0.01</td>
<td align="left">1%</td>
</tr>
<tr class="even">
<td align="left">Reference checks</td>
<td align="left">0.23</td>
<td align="left">0.61</td>
<td align="left">0.05</td>
<td align="left">9%</td>
</tr>
<tr class="odd">
<td align="left">Job experience (years)</td>
<td align="left">0.01</td>
<td align="left">0.56</td>
<td align="left">0.00</td>
<td align="left">0%</td>
</tr>
<tr class="even">
<td align="left">Biographical data</td>
<td align="left">0.30</td>
<td align="left">0.56</td>
<td align="left">0.00</td>
<td align="left">0%</td>
</tr>
<tr class="odd">
<td align="left">Years of education</td>
<td align="left">0.20</td>
<td align="left">0.60</td>
<td align="left">0.04</td>
<td align="left">7%</td>
</tr>
<tr class="even">
<td align="left">Interests</td>
<td align="left">0.18</td>
<td align="left">0.59</td>
<td align="left">0.03</td>
<td align="left">5%</td>
</tr>
</tbody>
</table>
<p>A similar table (table 3 below) may be constructed showing the criterion-related validity of methods for training performance.</p>
<caption>
<span id="tab:tabthree">Table 2.2: </span>
</caption>
<div custom-style="Table Caption">
<em>Table 3: Criterion-related Validity for Training Performance of Selection Methods, and GMA in combination with these methods Adapted From Schmidt &amp; Hunter (1998).</em>
</div>
<table>
<thead>
<tr class="header">
<th align="left">Personnel.measures</th>
<th align="left">Validity.rxy.</th>
<th align="left">Multiple.R</th>
<th align="left">Gain.in.validity.from.adding.supplement</th>
<th align="left">X..increase.in.Validity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">GMA tests</td>
<td align="left">0.56</td>
<td align="left">NA</td>
<td align="left">NA</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Integrity tests</td>
<td align="left">0.38</td>
<td align="left">0.67</td>
<td align="left">0.11</td>
<td align="left">20%</td>
</tr>
<tr class="odd">
<td align="left">Conscientiousness tests</td>
<td align="left">0.30</td>
<td align="left">0.65</td>
<td align="left">0.09</td>
<td align="left">16%</td>
</tr>
<tr class="even">
<td align="left">Employment interviews (all types)</td>
<td align="left">0.35</td>
<td align="left">0.59</td>
<td align="left">0.03</td>
<td align="left">5%</td>
</tr>
<tr class="odd">
<td align="left">Peer ratings</td>
<td align="left">0.36</td>
<td align="left">0.57</td>
<td align="left">0.01</td>
<td align="left">1%</td>
</tr>
<tr class="even">
<td align="left">Reference checks</td>
<td align="left">0.23</td>
<td align="left">0.61</td>
<td align="left">0.05</td>
<td align="left">9%</td>
</tr>
<tr class="odd">
<td align="left">Job experience (years)</td>
<td align="left">0.01</td>
<td align="left">0.56</td>
<td align="left">0.00</td>
<td align="left">0%</td>
</tr>
<tr class="even">
<td align="left">Biographical data</td>
<td align="left">0.30</td>
<td align="left">0.56</td>
<td align="left">0.00</td>
<td align="left">0%</td>
</tr>
<tr class="odd">
<td align="left">Years of education</td>
<td align="left">0.20</td>
<td align="left">0.60</td>
<td align="left">0.04</td>
<td align="left">7%</td>
</tr>
<tr class="even">
<td align="left">Interests</td>
<td align="left">0.18</td>
<td align="left">0.59</td>
<td align="left">0.03</td>
<td align="left">5%</td>
</tr>
</tbody>
</table>
<p>The validity coefficient (r_{xy}) for GMA given in table 2 is from an analysis involving over 32,000 employees in 515 diverse jobs (Hunter, 1980; Hunter and Hunter, 1984). This value of 0.51 is actually for ‘medium complexity’ jobs within the sample. Schmidt and Hunter (1998) state that this level of complexity includes 62% of all the jobs in the US economy. This level of job includes ‘skilled blue collar’ jobs and ‘mid-level white collar jobs’ such as upper level clerical and lower level administrative jobs. Within this diversity of ‘medium complexity’ jobs there was reported to be little variation around this value of 0.51. This analysis goes on to report that where validity coefficients did differ, this was for very different levels of job (see table 4 overleaf). Again, within each broad level of job there was reported to be little variation in validity coefficient.</p>
<caption>
<span id="tab:tabfour">Table 2.3: </span>
</caption>
<div custom-style="Table Caption">
<em>Table 4: How criterion-related validity coefficients vary across broad job- level (from Schmidt and Hunter, 1998)</em>
</div>
<table>
<thead>
<tr class="header">
<th align="left">Job.Level</th>
<th align="left">Validity.Coefficient</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Professional managerial</td>
<td align="left">0.58</td>
</tr>
<tr class="even">
<td align="left">High-level complex-technical</td>
<td align="left">0.56</td>
</tr>
<tr class="odd">
<td align="left">Medium complexity</td>
<td align="left">0.51</td>
</tr>
<tr class="even">
<td align="left">Semi-skilled</td>
<td align="left">0.40</td>
</tr>
<tr class="odd">
<td align="left">Completely unskilled</td>
<td align="left">0.23</td>
</tr>
</tbody>
</table>
<p>This analysis suggests that GMA test validity is generally high. Furthermore, the analysis revealed little variation in the validity of ability tests within very broad job families, and thus tests may be said to have considerable validity generalization.</p>
<p>The above U.S. work has been supported by more recent European meta-analyses (e.g. Bertua, Anderson &amp; Salgado, 2005; Salgado, Anderson, Moscoso, Silvia, de Fruyt &amp; Rolland, 2003). Salgado et al (2003) report validity for GMA measures across 12 occupational categories in the European Community. They report large validities for job performance and training success in 11 of these categories. Here again, job complexity (low, medium or high) moderated the size of these coefficients. The authors report that these findings are similar to those found in the U.S., although the European data revealed slightly higher validity coefficients in some cases.</p>
</div>
<div id="validity-generalization-and-meta-analysis" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Validity Generalization and Meta-analysis<a href="intro.html#validity-generalization-and-meta-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The above picture of generally high and stable validity coefficients is quite different from the general view of ability tests held until the late 1970s. Then, it was generally believed that the criterion-related validity of ability tests was both generally low (i.e. around 0.3) and situationally specific. That is, the validity for a given type of test seemed to be quite different for slightly different job roles and even different locations.
However, most of the studies, and especially early studies, used small sample sizes. Because of the small sample sizes involved in any one study, any single study may slightly overestimate or underestimate the ‘real’ relationship between tests and criterion. This is a type of sampling error, which can give rise to seemingly situationally specific validity coefficients. Combining the results of these smaller studies allows the researcher take account of this sampling error and evaluate the extent to which there are real differences between coefficients across job roles and locations. This was the method used by Schmidt and Hunter above which found little ‘real’ variation in coefficients within very broad job families. This method of combining many small studies is termed ’meta-analysis’ and allows for an evaluation of validity generalization. Meta-analysis is often termed validity generalization within psychological testing.
Often validity generalization results are also ‘statistically adjusted’ so as to take account of the reliability of the criterion measurement. Low reliability in criterion measurement will lower any correlation between test and criterion. Validity generalization techniques also take account of differences between job applicants and job incumbents. This is because criterion-related coefficients can only be calculated once people are performing the job. Thus, if the test was used within selection, then the coefficient calculated will not include the whole range of test scores that were found within the applicants. This, in turn, will lead to an underestimation of the ‘real’ relationship between test scores and future job performance. See figure 1 for an illustration of this effect.</p>
<div class="figure"><span style="display:block;" id="fig:figone"></span>
<img src="Floats/Ch1/Fig1.png" alt="Figure 1: An Illustration of the effect of changing the range of test scores on the correlation between test scores and criterion" width="355" />
<p class="caption">
Figure 2.2: Figure 1: An Illustration of the effect of changing the range of test scores on the correlation between test scores and criterion
</p>
</div>
<p>The technique of validity generalisation can upwardly adjust the observed validity coefficients so as to allow for the restricted range of scores found within job incumbents compared to job applicants. This adjustment was used by Schmidt and Hunter to construct the previous tables of validity coefficients and, as we have seen, this gives rise to quite high ability test validity. Cook (1998) suggests that these corrections give ‘estimated mean true validity’ of about twice the mean uncorrected validity.</p>
</div>
<div id="implications-from-validity-generalization" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Implications from Validity Generalization<a href="intro.html#implications-from-validity-generalization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The technique of validity generalization has revealed that similar tests have quite stable validities for very broad job families. Thus, test users can have some confidence that if a test has evidence of validity for a particular job role, then there is likely to be validity with similar tests in similar job roles.
Thus it may be reasonable to assume that test validity information obtained in one situation may generalize to similar situations.
Nevertheless, when generalizing from specific validity information, one should check that:</p>
<p>• The conditions of the original validity study are similar to the conditions to which one wishes to generalise. For example, a test for the selection of supervisors in an industry with mostly male employees may not show the same validity when used to select supervisors for more mixed industries.</p>
<p>• The criterion is similar (e.g. rate of product production may be quite different to supervisor ratings).</p>
<p>• The original validation sample size is adequate.</p>
<p>• There is a check for restricted range on both test and criterion within the original validation study.</p>
<p>• Differential prediction has been considered (i.e. validities may differ for different groups of people).</p>
</div>
<div id="determinants-of-job-performance" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Determinants of Job Performance<a href="intro.html#determinants-of-job-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>According to Schmidt and Hunter (1992), mental ability has a direct causal impact on the acquisition of job knowledge which in turn leads to higher job performance. They claim that mental ability also has a smaller direct effect upon job performance. These authors also state that job experience, up to about 5 years, operates in the same way, with the major effect of job experience being on job knowledge. Finally, they claim that personality, in particular conscientiousness, also influences job knowledge and thus job performance.</p>
<div class="figure"><span style="display:block;" id="fig:figtwo"></span>
<img src="Floats/Ch1/Fig2.png" alt="Figure 2: An Illustration of the suggested relationships between Job Performance and its Determinants (constructed from Schmidt &amp; Hunter, 1992)" width="252" />
<p class="caption">
Figure 2.3: Figure 2: An Illustration of the suggested relationships between Job Performance and its Determinants (constructed from Schmidt &amp; Hunter, 1992)
</p>
</div>
<p>The above model gives an important role to job experience, up to the first 5 years. Schmidt, Hunter and Outerbridge (1986) report that when experience does not exceed 5 years, the correlation between experience and job performance is around 0.4. These authors report that after 5 years the correlation becomes increasingly weak, with further increases in job experience leading to little improvement in job performance. Thus, as shown previously in table 2 (p.10), the overall validity of job experience for predicting job performance is only 0.18. Table 2 was based on a meta-analysis that included a wide variety of experience, from less than 6 months to more than 30 years. This pattern of relationship, where there is initially a rather strong linear relationship between the predictor and criterion, which then breaks down at the higher end of predictor scores, is termed a twisted pear relationship (Fisher, 1959). Such a relationship is quite common within psychometrics and is illustrated in figure 3.</p>
<div class="figure"><span style="display:block;" id="fig:figthree"></span>
<img src="Floats/Ch1/Fig3.png" alt="Figure 3: An illustration of a twisted pear relationship. Scores on the criterion (Y) and the predictor (X) are quite strongly correlated at the lower end of predictor scores, but there is no correlation at the higher end of predictor scores." width="302" />
<p class="caption">
Figure 2.4: Figure 3: An illustration of a twisted pear relationship. Scores on the criterion (Y) and the predictor (X) are quite strongly correlated at the lower end of predictor scores, but there is no correlation at the higher end of predictor scores.
</p>
</div>
</div>
<div id="what-is-meant-by-general-mental-ability-gma" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> What is meant by General Mental Ability (GMA)<a href="intro.html#what-is-meant-by-general-mental-ability-gma" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>General mental ability is thought to underlie performance on a whole range of ability tests. Spearman (1927) argued that differences in general mental ability are a result of differences in three basic mental processes: the apprehension of experience, the eduction of relations and the eduction of correlates. As an example, consider the simple problem presented below:
Ankle is to foot as wrist is to?</p>
<p>To solve this analogy, there must first be a perception and understanding of the terms based on past experience (apprehension of experience). Secondly, there must be an inferring of the relationship between the terms (eduction of relationships). Thirdly, there must be an inferring of the missing term so as to satisfy the same relationship (eduction of correlates). For Spearman, then, general mental ability is, in short, the ability to ‘figure things out’. Though this may not seem to give much insight into the meaning of mental ability, this description would satisfy many people currently involved in the field of ability measurement.</p>
</div>
<div id="criterion-related-validity-coefficients-and-the-coefficient-of-determination" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Criterion-related Validity Coefficients and the Coefficient of Determination<a href="intro.html#criterion-related-validity-coefficients-and-the-coefficient-of-determination" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Criterion-related validity coefficients tell us about the strength of relationship between the test and the criterion, from 0, where there is no relationship, up to 1.00, where there is a perfect relationship between the two sets of scores. A more concrete understanding of this coefficient can be obtained by converting it to what is known as the coefficient of determination. This coefficient of determination is simply the square of the criterion-related validity coefficient, and tells us the proportion of criterion performance that is predicted by the test. Thus, if a validity coefficient (rxy) is calculated as 0.5, then the coefficient of determination (rxy2) will equal 0.25. That is for a validity coefficient of 0.5, then 0.25 (or 25%) of criterion performance is predictable from the test scores. Another way of saying this is that there is 25% overlap between the two sets of scores. Figure 4 below shows the extent of overlap between a set of test scores and a set of criterion scores that correlate at 0.5.</p>
<div class="figure"><span style="display:block;" id="fig:figfour"></span>
<img src="Floats/Ch1/Fig4.png" alt="Figure 4: An illustration of the 25% overlap between test scores and criterion scores when the two sets of scores correlate at 0.5." width="226" />
<p class="caption">
Figure 2.5: Figure 4: An illustration of the 25% overlap between test scores and criterion scores when the two sets of scores correlate at 0.5.
</p>
</div>
</div>
<div id="criterion-related-validity-and-multiple-correlation" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Criterion-Related Validity and Multiple-Correlation<a href="intro.html#criterion-related-validity-and-multiple-correlation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is unlikely that just one test would be used to select people. Many scores can be combined to give the best prediction for any given criterion. The correlation between a criterion and multiple tests (or predictors) can be established using multiple correlation. The multiple correlation coefficient (R) gives an indication of the extent to which adding more tests gives incremental validity</p>
<p>The square of the multiple-correlation coefficient (R2) will again give the coefficient of determination. In fact, if just two tests (or predictors) are used, R2 can be calculated directly using equation 1 below:</p>
<p>Equation 1:</p>
<p><span class="math display">\[
\huge R^2_{c.12} = \frac{r_{c1}^2+r_{c2}^2-2r_{12}r_{c1}r_{c2}} {1-r^2_{12}}
\]</span></p>
<p>Where:
<span class="math inline">\(R^2\)</span> is the coefficient of determination for the criterion (c) on the basis of predictors 1 and 2</p>
<p><span class="math inline">\(r_{c1}\)</span> is the correlation between the criterion and test (predictor) 1</p>
<p><span class="math inline">\(r_{c2}\)</span> is the correlation between the criterion and test (predictor) 2</p>
<p><span class="math inline">\(r_{12}\)</span> is the correlation between test 1 and test 2</p>
<p>Consider the following example where:
• There is a correlation of 0.51 between the criterion of Job performance and the predictor of General Mental Ability (GMA).
• There is also a correlation of 0.54 between the criterion of Job Performance and the predictor of Work Sample (WS).
• Finally there is a correlation between the two predictors (GMA and WS) of 0.38.
Then:</p>
<p><span class="math display">\[
\huge R^2_{c.12} = \frac{.51_{c1}^2+.54_{c2}^2-2\times .38_{12}.51_{c1}.54_{c2}} {1-.38^2_{12}}
\]</span></p>
<p><span class="math display">\[
\huge R^2_{c.12} = 0.4 = 40\%
\]</span></p>
<p>In this example then, the coefficient of determination for the criterion of Job Performance is 0.4 or 40%. That is, 40% of the variability in job performance is predictable from the two predictors combined.</p>
<p>Furthermore, the multiple-correlation coefficient (R) can be determined from this coefficient of determination by simply taking the square root of the coefficient of determination. In the above example:</p>
<p>Since <span class="math inline">\(\huge R^2_{c.12} = 0.4 = 40\%\)</span> then <span class="math inline">\(R_c{12} = \sqrt{0.4} = 0.63\)</span>.</p>
<p>If the reader refers back to Table 2 on page 4, it can be seen that multiple-correlation coefficient given for the combination of GMA and WS in the prediction of Overall Job Performance is in fact 0.63. The original paper from which Table 2 was constructed gives the necessary three terms of equation 1, including the correlation between GMA and Work Sample of 0.38 (not shown on table 2), from which the multiple-correlation may be derived as above.</p>
<p>Although equation 1 may look rather complicated, it can be represented in the form of a Venn diagram (Figure 5 overleaf) which illustrates the relationships between correlations as overlapping spaces.</p>
<div class="figure"><span style="display:block;" id="fig:figfive"></span>
<img src="Floats/Ch1/Fig5.png" alt="Figure 5: An illustration of a multiple-correlation between the predictors of General mental ability (GMA) and Work Sample Tests (WM) and the criterion of Overall Job Performance." width="247" />
<p class="caption">
Figure 2.6: Figure 5: An illustration of a multiple-correlation between the predictors of General mental ability (GMA) and Work Sample Tests (WM) and the criterion of Overall Job Performance.
</p>
</div>
</div>
<div id="indicative-general-references-on-selection" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Indicative General References on Selection<a href="intro.html#indicative-general-references-on-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Beier, M.E., &amp; Oswald, F.L. (2012) Is cognitive ability a liability? A critique and future research agenda on skilled performance. Journal of Experimental Psychology: Applied, 18, 4, 331-345.</p>
<p>Bertua, C., Anderson, N. &amp; Salgado, J.F. (2005). The Predictive Validity of Cognitive Ability Tests: A UK Meta-Analysis. Journal of Occupational and Organizational Psychology, 78, 387-409.</p>
<p>Bozionelos, N. (2005). When the inferior candidate is offered the job: The selection interview as a political and power game. Human Relations,58(12),1605–1631.</p>
<p>Christian, M. S., Edwards, B. D., &amp; Bradley, J. C. (2010). Situational judgment tests: Constructs assessed and a meta-analysis of their criterion-related validities. Personnel Psychology, 63(1), 83–117. Retrieved from <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.2009.01163.x/full" class="uri">http://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.2009.01163.x/full</a></p>
<p>Cook, M. (2009). Personnel Selection: Adding Value through People (5th ed). Chichester: John Wiley &amp; Sons.</p>
<p>Cortina, J. M., Goldstein, N. B., Payne, S. C., Davison, H. K., &amp; Gilliland, S. W. (2000). The incremental validity of interview scores over and above cognitive ability and conscientiousness scores. Personnel Psychology, 53(2), 325–351. Retrieved from <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.2000.tb00204.x/abstract" class="uri">http://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.2000.tb00204.x/abstract</a></p>
<p>Hough, L.M. &amp; Oswald, F.L. (2000). Personnel Selection: Looking Toward the Future – Remembering the Past. Annual Review of Psychology, 51, 631-664.</p>
<p>Krause, D.E., Kersting, M., Heggestad, E.D. &amp; Thornton III, G.C. (2006). Incremental Validity of Assessment Center Ratings Over Cognitive Ability Tests: A Study at the Executive Management Level. International Journal of Selection and Assessment, 14, 360-371.
Kuncel, N.R. &amp; Hezlett, S.A. (2010) Fact and Fiction in Cognitive Ability Testing for Admissions and Hiring Decisions. Current Directions in Psychological Science, 19, 6, 339-345
<a href="http://intl-cdp.sagepub.com/content/19/6/339.full" class="uri">http://intl-cdp.sagepub.com/content/19/6/339.full</a></p>
<p>Kuncel, N.R., Ones, D.S., &amp; Sackett, P.R. (2010). Individual differences as predictors of work, educational, and broad life outcomes. Personality and Individual Differences, 49, 4, 331-336.
<a href="http://www.sciencedirect.com/science/article/pii/S0191886910001765" class="uri">http://www.sciencedirect.com/science/article/pii/S0191886910001765</a></p>
<p>Lievens, F., &amp; Patterson, F. (2011). The validity and incremental validity of knowledge tests, low-fidelity simulations, and high-fidelity simulations for predicting job performance in advanced-level high-stakes selection. Journal of Applied Psychology, 96(5), 927–940. <a href="https://doi.org/10.1037/a0023496" class="uri">https://doi.org/10.1037/a0023496</a></p>
<p>Macan, T. (2009). The employment interview: A review of current studies and directions for future research. Human Resource Management Review, 19(3), 203–218. <a href="https://doi.org/10.1016/j.hrmr.2009.03.006" class="uri">https://doi.org/10.1016/j.hrmr.2009.03.006</a></p>
<p>Piotrowski, C. &amp; Armstrong, T. (2006). Current Recruitment and Selection Practices: A National Survey of Fortune 1000 Firms. North American Journal of Psychology, 8, 489-496.</p>
<p>Ployhart, R.E. (2006). Staffing in the 21st Century: New Challenges and Strategic Opportunities. Journal of Management, 32(6), 868-897.</p>
<p>Robertson, I.T. &amp; Smith, M. (2001). Personnel Selection. Journal of Occupational and Occupational Psychology, 74, 441-472.</p>
<p>Rothstein, M. G., &amp; Goffin, R. D. (2006). The use of personality measures in personnel selection: What does current research support? Human Resource Management Review, 16(2), 155–180. <a href="https://doi.org/10.1016/j.hrmr.2006.03.004" class="uri">https://doi.org/10.1016/j.hrmr.2006.03.004</a></p>
<p>Ryan, A. M., &amp; Ployhart, R. E. (2014). A Century of Selection. Annual Review of Psychology, 65(1), 693–717. <a href="https://doi.org/10.1146/annurev-psych-010213-115134" class="uri">https://doi.org/10.1146/annurev-psych-010213-115134</a></p>
<p>Sackett, P.R., &amp; Lievens, F. (2008). Personnel selection. Annual Review of Psychology, 59, 419-50. <a href="http://www.numerons.in/files/documents/Personnel-Selection-Paul-R.-Sackett-and-Filip-Lievens.pdf" class="uri">http://www.numerons.in/files/documents/Personnel-Selection-Paul-R.-Sackett-and-Filip-Lievens.pdf</a></p>
<p>Salgado, J.F., Anderson, N., Moscoso, S., Silvia, B.C., de Fruyt, F. &amp; Rolland, J.P. (2003). A Meta-Analytic Study of General Mental Ability Validity for Different Occupations in the European Community. Journal of Applied Psychology, 88, 1068-1081.</p>
<p>Salgado, J. F. (2016). A Theoretical Model of Psychometric Effects of Faking on Assessment Procedures: Empirical findings and implications for personality at work. International Journal of Selection and Assessment, 24(3), 209–228. Retrieved from <a href="http://onlinelibrary.wiley.com/doi/10.1111/ijsa.12142/full" class="uri">http://onlinelibrary.wiley.com/doi/10.1111/ijsa.12142/full</a></p>
<p>Schmitt, N. (2014). Personality and Cognitive Ability as Predictors of Effective Performance at Work. Annual Review of Organizational Psychology and Organizational Behavior, 1(1), 45–65. <a href="https://doi.org/10.1146/annurev-orgpsych-031413-091255" class="uri">https://doi.org/10.1146/annurev-orgpsych-031413-091255</a></p>
<p>Schmidt, F. (2006). The Orphan Area for Meta-Analysis: Personnel Selection Retrieved October 30, 2016, from <a href="http://www.siop.org/tip/Oct06/05schmidt.aspx" class="uri">http://www.siop.org/tip/Oct06/05schmidt.aspx</a></p>
<p>Schmidt, F.L. &amp; Hunter, J.E. (1998). The Validity and Utility of Selection Methods in Personnel Psychology: Practical and Theoretical Implications of 85 Years of Research Findings. Psychological Bulletin, 124, 262-274.</p>
<p>Schmidt, F.L. &amp; Hunter, J.E. (2004). General Mental Ability in the World of Work: Occupational Attainment and Job Performance. Journal of Personality and Social Psychology, 86,162-173.</p>
<p>Scior, K., Bradley, C. E., Potts, H. W. W., Woolf, K., &amp; de C Williams, A. C. (2014). What predicts performance during clinical psychology training? British Journal of Clinical Psychology, 53(2), 194–212. <a href="https://doi.org/10.1111/bjc.12035" class="uri">https://doi.org/10.1111/bjc.12035</a></p>
<p>Scroggins, W. A., Thomas, S. L., &amp; Morris, J. A. (2008). Psychological testing in personnel selection, part II: The refinement of methods and standards in employee selection. Public Personnel Management, 37(2), 185–198. Retrieved from <a href="http://ppm.sagepub.com/content/37/2/185.short" class="uri">http://ppm.sagepub.com/content/37/2/185.short</a></p>
<p>Scroggins, W. A., Thomas, S. L., &amp; Morris, J. A. (2009). Psychological testing in personnel selection, part III: The resurgence of personality testing. Public Personnel Management, 38(1), 67–77. Retrieved from <a href="http://ppm.sagepub.com/content/38/1/67.short" class="uri">http://ppm.sagepub.com/content/38/1/67.short</a></p>
<p>Smith, M. &amp; Smith, P. (2005). Testing People at Work: Competencies in Psychometric Testing. Oxford: BPS Blackwell.</p>
<p>Zibarras, L.D., &amp; Woods, S.A. (2010). A Survey of UK Selection Practices Across Different Organization Sizes and Industry Sectors. Journal of Occupational and Organizational Psychology, 83, 499-511.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="NDSM.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Rowley.pdf", "Rowley.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
